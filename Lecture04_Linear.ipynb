{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungsdew/-/blob/main/Lecture04_Linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5WlM_3Y7sHgC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "\n",
        "MNIST_ROOT = \"/content/MNIST\"\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUa9x1UPsXaQ",
        "outputId": "e2d3076c-87bf-44e5-e9df-8bab8fc98623"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/MNIST\n",
        "\n",
        "!unzip -qq \"/content/drive/MyDrive/MNIST.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPnEne7qsmqi",
        "outputId": "c2b0415b-8680-4160-f8a9-e4c3bfb72242"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/MNIST'\n",
            "/content\n",
            "replace train/0/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snvvZbTCsHgH",
        "outputId": "a493f2a8-8178-4dfb-f4f3-3c12a51189c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MNIST/val\n",
            "---------------------/6 number : 958\n",
            "---------------------/7 number : 1028\n",
            "---------------------/5 number : 892\n",
            "---------------------/0 number : 980\n",
            "---------------------/1 number : 1135\n",
            "---------------------/3 number : 1010\n",
            "---------------------/9 number : 1009\n",
            "---------------------/8 number : 974\n",
            "---------------------/2 number : 1032\n",
            "---------------------/4 number : 982\n",
            "/content/MNIST/train\n",
            "---------------------/6 number : 5918\n",
            "---------------------/7 number : 6265\n",
            "---------------------/5 number : 5421\n",
            "---------------------/0 number : 5923\n",
            "---------------------/1 number : 6742\n",
            "---------------------/3 number : 6131\n",
            "---------------------/9 number : 5949\n",
            "---------------------/8 number : 5851\n",
            "---------------------/2 number : 5958\n",
            "---------------------/4 number : 5842\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 구조도\n",
        "for phase in os.listdir(MNIST_ROOT):\n",
        "    print(MNIST_ROOT+\"/\"+phase)\n",
        "    for dir in os.listdir(os.path.join(MNIST_ROOT, phase)):\n",
        "        print(f\"---------------------/\", end=\"\")\n",
        "        print(dir, f\"number : {len(os.listdir(os.path.join(MNIST_ROOT, phase, dir)))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_gDxVmqsHgI"
      },
      "source": [
        "# torch.utils.data.Dataset 소개\n",
        "\n",
        "PyTorch에서 `torch.utils.data.Dataset`은 데이터셋을 나타내는 클래스입니다. 이 클래스는 데이터에 대한 접근과 조작을 효율적으로 수행할 수 있는 인터페이스를 제공합니다. `Dataset` 클래스는 데이터와 모델 사이의 연결고리 역할을 합니다.\n",
        "\n",
        "## 주요 기능\n",
        "1. **데이터 로딩**: `Dataset`은 파일, 데이터베이스, API 등 다양한 소스에서 데이터를 편리하게 로딩할 수 있는 방법을 제공합니다. 이를 통해 특정 요구에 맞게 데이터 로딩 과정을 사용자 정의할 수 있습니다.\n",
        "\n",
        "2. **데이터 변환**: `Dataset`은 데이터에 전처리, 데이터 증강, 특성 엔지니어링 등의 변환을 실시간으로 적용할 수 있습니다. 이러한 변환은 데이터 로딩 파이프라인에 원활하게 통합될 수 있습니다.\n",
        "\n",
        "3. **데이터 접근**: `Dataset`은 색인을 사용하여 개별 데이터 샘플에 효율적으로 접근할 수 있는 방법을 제공합니다. 데이터에 대해 무작위 또는 순차적인 접근을 허용하므로 배치 처리 및 단일 샘플 처리에 모두 적합합니다.\n",
        "\n",
        "## 커스텀 데이터셋 생성하기\n",
        "`torch.utils.data.Dataset`을 사용하기 위해선, `Dataset` 클래스를 상속받고 두 가지 중요한 메서드를 구현하는 방식으로 커스텀 데이터셋을 생성할 수 있습니다:\n",
        "\n",
        "1. `__len__()`: 이 메서드는 데이터셋의 크기, 즉 총 샘플 수를 반환합니다.\n",
        "\n",
        "2. `__getitem__(index)`: 이 메서드는 주어진 인덱스에 해당하는 샘플을 반환합니다. 데이터를 로딩하고 필요한 변환을 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhGXX-G6sHgN",
        "outputId": "8307be1a-7cc9-4f53-cd4e-427d470db0af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length = 10000\n",
            "Channel = 1, Height = 28, Width = 28\n",
            "sample_target = <class 'int'>, 0\n"
          ]
        }
      ],
      "source": [
        "# 이미지를 읽는 함수 정의\n",
        "def get_image(p: str):\n",
        "    return Image.open(p).convert(\"L\")\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class baseDataset(Dataset):\n",
        "    def __init__(self, root: str, train: bool):\n",
        "        super().__init__()\n",
        "\n",
        "        # 훈련 데이터셋 또는 검증 데이터셋의 루트 디렉토리 설정\n",
        "        if train:\n",
        "            self.root = os.path.join(root, \"train\")\n",
        "            self.transform = T.Compose([\n",
        "                T.ToTensor()\n",
        "            ])\n",
        "        else:\n",
        "            self.root = os.path.join(root, \"val\")\n",
        "            self.transform = T.Compose([\n",
        "                T.ToTensor()\n",
        "            ])\n",
        "\n",
        "        # 데이터 리스트 생성\n",
        "        data_list = []\n",
        "        for i in range(10):\n",
        "            dir = os.path.join(self.root, str(i))\n",
        "            for img in os.listdir(dir):\n",
        "                img_path = os.path.join(dir, img)\n",
        "                data_list.append((i, img_path))\n",
        "        self.data_list = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터셋의 총 데이터 개수 반환\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        # 인덱스에 해당하는 데이터 반환\n",
        "        number, img_path = self.data_list[idx]\n",
        "\n",
        "        # 이미지 파일을 PIL 객체로 읽어들이고, 그레이스케일로 변환한 후 텐서로 변환\n",
        "        img_obj = get_image(img_path)\n",
        "        img_tensor = self.transform(img_obj)\n",
        "\n",
        "        return img_tensor, number\n",
        "\n",
        "# baseDataset 테스트\n",
        "test_dataset = baseDataset(MNIST_ROOT, False)  # 검증 데이터셋 객체 생성\n",
        "print(f\"length = {len(test_dataset)}\")  # 데이터셋의 총 데이터 개수 출력\n",
        "\n",
        "sample_tensor, sample_target = test_dataset[10]  # 인덱스 10에 해당하는 데이터 샘플 가져오기\n",
        "C, H, W = sample_tensor.shape  # 텐서의 채널, 높이, 너비 출력\n",
        "print(f\"Channel = {C}, Height = {H}, Width = {W}\")\n",
        "print(f\"sample_target = {type(sample_target)}, {sample_target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIPTXraPsHgP"
      },
      "source": [
        "# Multi-Layer Perceptron (다층 퍼셉트론)\n",
        "\n",
        "Multi-Layer Perceptron(MLP)은 인공신경망의 가장 기본적인 형태로, 여러 개의 은닉층(hidden layer)으로 구성된 다층 구조의 신경망입니다. MLP는 입력층(input layer), 은닉층(hidden layer), 출력층(output layer)으로 구성되며, 각 층은 여러 개의 뉴런으로 구성됩니다.\n",
        "\n",
        "주요 특징과 동작 원리는 다음과 같습니다:\n",
        "\n",
        "- **다층 구조**: MLP는 여러 개의 은닉층을 가지는 다층 구조로 이루어져 있습니다. 은닉층은 입력층과 출력층 사이에 위치하며, 입력층의 정보를 받아 처리한 후 출력층으로 전달합니다.\n",
        "\n",
        "- **비선형성 적용**: MLP는 각 은닉층과 출력층에 비선형 활성화 함수를 적용합니다. 이 비선형성은 MLP가 복잡한 함수를 모델링할 수 있도록 하며, 선형 모델로는 표현하기 어려운 비선형 관계를 학습할 수 있게 합니다.\n",
        "\n",
        "- **전방향 전파**: MLP는 입력층에서부터 은닉층을 거쳐 출력층으로 데이터를 전달하는 전방향 전파(forward propagation)를 수행합니다. 입력 데이터는 각 은닉층을 통과하면서 가중치와 편향에 의해 변환되고, 활성화 함수를 통과하여 출력층으로 전달됩니다.\n",
        "\n",
        "- **가중치 업데이트**: MLP는 역전파 알고리즘을 사용하여 가중치를 업데이트합니다. 역전파 알고리즘은 손실 함수의 그래디언트를 계산하고, 이를 이용하여 가중치를 조정하여 손실을 최소화하는 방향으로 모델을 학습시킵니다.\n",
        "\n",
        "- **다중 분류와 회귀**: MLP는 다중 클래스 분류와 회귀 문제에 모두 사용될 수 있습니다. 다중 클래스 분류에서는 출력층의 뉴런 수가 클래스 수와 일치하며, 각 뉴런은 해당 클래스에 대한 확률을 나타냅니다. 회귀 문제에서는 출력층의 뉴런 수가 1이며, 예측한 값을 출력합니다.\n",
        "\n",
        "- **학습과 일반화**: MLP는 주어진 입력과 정답(label)을 사용하여 가중치를 학습시킵니다. 학습된\n",
        "\n",
        " MLP는 새로운 입력에 대한 예측을 수행할 수 있으며, 학습 데이터에 대한 정확도를 넘어서 일반화(generalization)된 예측을 수행합니다.\n",
        "\n",
        "MLP는 다층 구조와 비선형 활성화 함수를 통해 복잡한 함수를 모델링할 수 있는 강력한 신경망입니다. 이를 통해 이미지 분류, 텍스트 분류, 회귀 등 다양한 머신러닝과 딥러닝 문제를 해결할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rBIdeKcsHgQ"
      },
      "source": [
        "# torch.nn.Module 소개\n",
        "\n",
        "`torch.nn.Module`은 PyTorch에서 신경망 모델을 구성하는 데 사용되는 핵심 클래스입니다. 이 클래스를 활용하여 다양한 신경망 계층을 정의하고 연결하여 모델을 구축할 수 있습니다.\n",
        "\n",
        "## 주요 기능\n",
        "1. **신경망 계층 정의**: `Module`을 상속하여 사용자 정의 신경망 계층을 구현할 수 있습니다. 각 계층은 `forward()` 메서드를 통해 입력을 받고 출력을 반환합니다.\n",
        "\n",
        "2. **파라미터 관리**: `Module`은 자체적으로 파라미터를 관리합니다. 각 계층의 학습 가능한 가중치와 편향은 모델 내부에서 자동으로 추적되며, 최적화 과정에서 업데이트됩니다.\n",
        "\n",
        "3. **순전파 (Forward Propagation)**: `Module`을 통해 정의한 신경망은 순전파를 통해 입력 데이터를 출력으로 변환합니다. `forward()` 메서드에서 계층을 연결하고 데이터를 처리하여 출력을 생성합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYNmjJeCsHgR"
      },
      "source": [
        "# nn.Sequential 소개\n",
        "\n",
        "`nn.Sequential`은 PyTorch에서 신경망 모델을 구성하기 위해 사용되는 클래스입니다. 이 클래스는 여러 개의 신경망 계층을 연속적으로 연결하여 모델을 간단하게 정의할 수 있는 도구입니다.\n",
        "\n",
        "## 주요 특징\n",
        "1. **계층 순차적 구성**: `nn.Sequential`은 순차적으로 여러 개의 신경망 계층을 정의할 수 있습니다. 계층은 순서대로 연결되어 입력 데이터를 처리하고 출력을 생성합니다.\n",
        "\n",
        "2. **간편한 모델 정의**: `nn.Sequential`은 직관적이고 간단한 방식으로 모델을 정의할 수 있습니다. 계층을 리스트 또는 OrderedDict 형태로 전달하여 모델을 구성할 수 있습니다.\n",
        "\n",
        "3. **자동적인 순전파**: `nn.Sequential`은 입력 데이터를 전달하면 내부적으로 순전파를 자동으로 수행합니다. 계층을 차례대로 통과하여 출력을 생성하므로 개별 계층을 직접 호출할 필요가 없습니다.\n",
        "\n",
        "## 사용법\n",
        "`nn.Sequential`을 사용하기 위해서는 계층을 차례대로 나열하여 전달해야 합니다. 아래는 `nn.Sequential`을 사용하여 모델을 정의하는 예시입니다:\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "# 모델 정의\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, output_size),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "```\n",
        "\n",
        "위 예시에서 `nn.Sequential`은 입력 데이터를 받아 각 계층을 차례로 통과시키고 최종 출력을 생성하는 모델을 정의합니다. 각 계층은 리스트 안에 순서대로 나열됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byl00a1KsHgT"
      },
      "source": [
        "# Activation Function의 역할\n",
        "\n",
        "Activation Function(활성화 함수)은 Deep Neural Network(DNN)에서 중요한 역할을 수행합니다. Activation Function은 신경망의 각 뉴런에 적용되며, 입력 신호를 비선형적으로 변환하여 네트워크의 표현력을 향상시킵니다. 아래는 Activation Function의 주요 역할에 대한 설명입니다:\n",
        "\n",
        "1. **비선형성 표현**: Activation Function은 신경망에 비선형성을 주어 선형 모델로는 표현할 수 없는 복잡한 함수를 학습할 수 있도록 합니다. 비선형성은 신경망이 다양한 종류의 데이터 패턴을 학습하고 복잡한 결정 경계를 생성할 수 있도록 돕습니다.\n",
        "\n",
        "2. **신경망의 표현력 증가**: Activation Function은 신경망이 다양한 함수를 근사할 수 있도록 합니다. 비선형 함수를 통과한 출력은 다음 레이어로 전달되며, 이를 통해 네트워크는 더 다양하고 복잡한 함수를 모델링할 수 있게 됩니다.\n",
        "\n",
        "3. **Gradient의 전파**: Activation Function은 역전파(Backpropagation) 과정에서 그래디언트(Gradient)를 적절하게 전달할 수 있도록 합니다. 비선형 함수의 도함수를 계산하고, 이를 통해 이전 레이어로 그래디언트를 역전파하여 학습을 진행할 수 있습니다.\n",
        "\n",
        "4. **출력의 정규화**: Activation Function은 출력값의 범위를 제한하여 모델의 안정성을 향상시킵니다. 예를 들어, Sigmoid Activation Function은 출력값을 0과 1 사이로 제한하며, Hyperbolic Tangent (tanh) Activation Function은 -1과 1 사이로 제한합니다. 이를 통해 네트워크의 출력을 제한하고, 입력에 대한 모델의 민감도를 조절할 수 있습니다.\n",
        "\n",
        "일반적으로 사용되는 Activation Function으로는 Sigmoid, ReLU, tanh, Leaky ReLU 등이 있습니다. 이들 Activation Function은 각자의 특성과 장단점을 가지고 있으며, 문제에 맞게 선택되어 사용됩니다. Activation Function의 역할은 DNN의 성능과 수렴 속도에 큰 영향을 미치므로, 적절한 Activation Function의 선택은 모델의 효과적인 학습과 성능 향상에 중요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJrAQEaasHgW"
      },
      "source": [
        "Image Classification 모델에서 마지막 레이어에 Activation 함수를 사용하지 않는 이유는 다음과 같습니다:\n",
        "\n",
        "1. **Output Space의 제약**: 일반적으로 Image Classification 모델의 마지막 레이어는 클래스의 확률을 나타내기 위한 선형 레이어로 구성됩니다. 이 선형 레이어는 출력 공간을 정의하는데, 각 클래스에 해당하는 점수(또는 로짓)를 출력합니다. 이러한 점수는 클래스 확률을 계산하는 소프트맥스(softmax) 함수를 통과시킬 수 있습니다.\n",
        "\n",
        "2. **다중 클래스 분류**: 이미지 분류 작업에서 일반적으로 사용되는 손실 함수는 크로스 엔트로피(cross-entropy)입니다. 크로스 엔트로피 손실 함수는 클래스 확률과 실제 레이블 간의 차이를 계산하기 위해 소프트맥스 함수의 출력을 사용합니다. 따라서 마지막 레이어에는 소프트맥스 함수가 적용되지 않아도 됩니다.\n",
        "\n",
        "3. **모델의 안정성**: 일부 경우, 마지막 레이어에 활성화 함수를 적용하면 모델의 안정성에 영향을 줄 수 있습니다. 예를 들어, 소프트맥스 함수는 클래스 점수 간의 상대적 크기를 조정하는데, 이로 인해 모델의 출력이 과도하게 크거나 작아지는 문제를 일으킬 수 있습니다. 따라서 클래스 점수를 사용하여 확률을 계산하는 소프트맥스 함수를 적용하지 않고 마지막 레이어를 유지하는 것이 일반적입니다.\n",
        "\n",
        "요약하자면, Image Classification 모델에서는 마지막 레이어에 활성화 함수를 사용하지 않는 이유는 클래스 확률을 직접 계산하기 위해 선형 레이어를 사용하고, 소프트맥스 함수를 적용하지 않아도 크로스 엔트로피 손실 함수와 함께 사용할 수 있기 때문입니다. 또한, 모델의 안정성을 고려하여 활성화 함수의 부작용을 피하기 위해 마지막 레이어를 유지합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdWX7AZ6sHgX",
        "outputId": "227d1080-376b-4ce9-9e13-bfca93dbaf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 10])\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # 레이어들을 nn.ModuleList로 묶음\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(784, 256),  # 입력 크기: 784, 출력 크기: 256\n",
        "                nn.ReLU()  # ReLU Activation Function 적용\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Linear(256, 64),  # 입력 크기: 256, 출력 크기: 64\n",
        "                nn.ReLU()  # ReLU Activation Function 적용\n",
        "            ),\n",
        "            nn.Linear(64, 10)  # 입력 크기: 64, 출력 크기: 10\n",
        "        ])\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = x.flatten(start_dim=1)  # 2D 이미지를 1D 벡터로 펼치기\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)  # 각 레이어를 순차적으로 적용\n",
        "        return x\n",
        "\n",
        "# MLP 신경망 인스턴스 생성\n",
        "net = MLP()\n",
        "\n",
        "# 임의의 입력 데이터 생성\n",
        "random_input = torch.randn(16, 1, 28, 28)\n",
        "\n",
        "# MLP 신경망에 입력 데이터 전달하여 출력 얻기\n",
        "random_output = net(random_input)\n",
        "\n",
        "# 출력의 크기 출력\n",
        "print(random_output.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtQnns8dsHgZ"
      },
      "source": [
        "# torch.utils.data.DataLoader 소개\n",
        "\n",
        "`torch.utils.data.DataLoader`는 PyTorch에서 데이터셋을 미니배치(mini-batch)로 나누어 효율적으로 로딩하기 위한 유틸리티 클래스입니다. `DataLoader`는 데이터셋을 가져와서 병렬적으로 로딩하고 셔플링하며, 사용자가 정의한 변환 및 데이터 처리를 적용할 수 있도록 도와줍니다.\n",
        "\n",
        "## 주요 기능\n",
        "1. **데이터 로딩 및 셔플링**: `DataLoader`는 데이터셋을 로딩하고 자동적으로 미니배치로 분할합니다. 또한, 데이터를 셔플하여 학습 과정에서 데이터의 순서에 따른 편향을 줄여줍니다.\n",
        "\n",
        "2. **병렬 처리**: `DataLoader`는 데이터를 병렬적으로 로딩하여 데이터 로딩 속도를 향상시킵니다. 이를 통해 GPU와의 데이터 처리 병목 현상을 최소화하고, 학습 속도를 향상시킬 수 있습니다.\n",
        "\n",
        "3. **데이터 변환 및 처리**: `DataLoader`는 사용자가 정의한 변환 함수를 적용하여 데이터를 실시간으로 변환하고 처리할 수 있습니다. 예를 들어, 이미지 데이터에 대해 데이터 증강, 정규화, 임의 변환 등의 작업을 수행할 수 있습니다.\n",
        "\n",
        "4. **배치 처리**: `DataLoader`는 미니배치 단위로 데이터를 처리하여 효율적인 학습과 추론을 지원합니다. 미니배치 처리는 GPU의 병렬 처리 능력을 최대한 활용하며, 메모리 사용을 최적화합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyrIxxj6sHga"
      },
      "source": [
        "# 미니배치 (Mini-batch)에 대해\n",
        "\n",
        "미니배치(Mini-batch)는 데이터를 작은 그룹 단위로 나누어 처리하는 기법입니다. 딥러닝에서는 대량의 데이터를 한 번에 처리하는 것이 어려우므로, 미니배치를 사용하여 데이터를 일부씩 나누어 처리하게 됩니다.\n",
        "\n",
        "주요 개념과 특징은 다음과 같습니다:\n",
        "\n",
        "- **데이터 분할**: 미니배치는 전체 데이터셋을 작은 그룹으로 나누어 처리합니다. 이 그룹들은 동일한 크기를 가지며, 각각의 미니배치는 여러 개의 데이터 포인트로 구성됩니다.\n",
        "\n",
        "- **병렬 처리**: 미니배치는 병렬 처리를 통해 효율적으로 계산할 수 있습니다. 여러 데이터 포인트를 동시에 처리함으로써 GPU와 같은 병렬 컴퓨팅 환경을 최대한 활용하여 학습 속도를 향상시킬 수 있습니다.\n",
        "\n",
        "- **그래디언트(Gradient) 계산**: 미니배치는 역전파 알고리즘을 사용한 그래디언트 계산에 중요한 역할을 합니다. 미니배치 단위로 손실 함수를 계산하고, 그래디언트를 구한 후 이를 평균 또는 합계하여 전체 데이터셋의 그래디언트를 추정합니다.\n",
        "\n",
        "- **메모리 효율성**: 미니배치를 사용하면 한 번에 전체 데이터를 메모리에 로드할 필요가 없습니다. 전체 데이터셋이 아닌 작은 미니배치만 메모리에 유지하여 메모리 사용량을 줄이고, 대용량 데이터셋을 처리할 수 있습니다.\n",
        "\n",
        "미니배치는 모델의 학습과 추론에 널리 사용되는 중요한 개념입니다. 적절한 미니배치 크기를 선택하여 데이터를 효과적으로 처리하고, 학습 속도와 모델의 성능을 향상시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5Fyex9DsHga",
        "outputId": "904f5924-d4bf-4de2-e0bf-00bfb9180932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Batch - Image Shape: torch.Size([64, 1, 28, 28]) Label Shape: torch.Size([64])\n",
            "Validation Batch - Image Shape: torch.Size([64, 1, 28, 28]) Label Shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "# 데이터셋 정의\n",
        "train_dataset = baseDataset(MNIST_ROOT, True)\n",
        "val_dataset = baseDataset(MNIST_ROOT, False)\n",
        "\n",
        "# 데이터로더 정의\n",
        "train_loader = DataLoader(train_dataset, BATCH_SIZE, True)\n",
        "val_loader = DataLoader(val_dataset, BATCH_SIZE, True)\n",
        "\n",
        "\n",
        "# 데이터 로딩 및 확인하는 테스트 코드\n",
        "for images, labels in train_loader:\n",
        "    print(\"Train Batch - Image Shape:\", images.shape, \"Label Shape:\", labels.shape)\n",
        "    break\n",
        "    # 이미지와 레이블에 대한 추가적인 작업 수행 가능\n",
        "    # ...\n",
        "\n",
        "for images, labels in val_loader:\n",
        "    print(\"Validation Batch - Image Shape:\", images.shape, \"Label Shape:\", labels.shape)\n",
        "    break\n",
        "    # 이미지와 레이블에 대한 추가적인 작업 수행 가능\n",
        "    # ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataLoader()"
      ],
      "metadata": {
        "id": "WrhOKjfhA7eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuYpIk79sHgb"
      },
      "source": [
        "# 역전파를 이용한 파라미터 업데이트\n",
        "\n",
        "역전파(Backpropagation)는 인공신경망의 학습 과정에서 손실 함수에 대한 그래디언트(gradient)를 계산하여 파라미터를 업데이트하는 알고리즘입니다. 이 알고리즘은 오차를 역방향으로 전파하여 각 계층의 파라미터에 대한 그래디언트를 계산합니다. 아래는 역전파를 이용한 파라미터 업데이트 과정을 자세히 설명한 것입니다:\n",
        "\n",
        "1. **순전파**: 입력 데이터를 인공신경망에 주입하여 순전파를 진행합니다. 입력은 여러 계층을 거치며 각 계층은 가중치와 편향에 의해 변환됩니다. 활성화 함수를 통과하여 최종 출력을 얻습니다.\n",
        "\n",
        "2. **손실 함수 계산**: 순전파를 통해 얻은 출력과 실제 정답(label)을 비교하여 손실 함수를 계산합니다. 손실 함수는 모델의 예측과 실제 값 사이의 차이를 측정하는데 사용됩니다.\n",
        "\n",
        "3. **역전파**: 손실 함수의 그래디언트(gradient)를 계산하여 각 파라미터에 대한 손실 함수의 미분 값을 얻습니다. 역전파 알고리즘을 통해 각 계층을 거꾸로 통과하면서 그래디언트를 전파합니다.\n",
        "\n",
        "4. **파라미터 업데이트**: 그래디언트를 사용하여 파라미터를 업데이트합니다. 주로 경사 하강법(gradient descent)을 사용하며, 학습률(learning rate)과 같은 하이퍼파라미터를 설정하여 최적화 과정을 조절할 수 있습니다.\n",
        "\n",
        "    - 각 파라미터에 대해 다음과 같이 업데이트 수식을 적용합니다:\n",
        "      ```\n",
        "      파라미터 = 파라미터 - 학습률 * 그래디언트\n",
        "      ```\n",
        "\n",
        "5. **반복**: 순전파, 역전파, 파라미터 업데이트 과정을 반복하여 모델을 학습시킵니다. 이를 여러 번의 에포크(epoch) 동안 반복하여 모델의 성능을 향상시킵니다.\n",
        "\n",
        "역전파 알고리즘은 그래디언트를 통해 각 파라미터가 손실 함수에 대해 얼마나 기여하는지 계산합니다. 이를 통해 가중치와 편향을 조정하여 손실 함수를 최소화하\n",
        "\n",
        "고, 모델의 예측을 개선합니다. 학습률은 파라미터 업데이트의 크기를 조절하는 하이퍼파라미터로, 학습 속도와 수렴 속도에 영향을 미칩니다. 적절한 학습률을 선택하여 모델의 최적화 과정을 조절해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y92NuwOsHgb",
        "outputId": "fba05845-3484-45b2-c57d-5e2c8e5675ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3]\n",
            "  Train Loss: 1.6793, Train Accuracy: 56.47%\n",
            "  Val Loss: 0.7731, Val Accuracy: 80.64%\n",
            "Epoch [2/3]\n",
            "  Train Loss: 0.5568, Train Accuracy: 85.34%\n",
            "  Val Loss: 0.4242, Val Accuracy: 88.20%\n",
            "Epoch [3/3]\n",
            "  Train Loss: 0.3990, Train Accuracy: 88.88%\n",
            "  Val Loss: 0.3508, Val Accuracy: 89.98%\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3  # 총 에포크 수\n",
        "LR = 1e-2  # 학습률\n",
        "\n",
        "net = MLP().to(DEVICE)  # MLP 모델 초기화 및 디바이스 설정\n",
        "criterion = CrossEntropyLoss()  # 손실 함수 정의\n",
        "optimizer = SGD(net.parameters(), lr=LR)  # 옵티마이저 정의\n",
        "\n",
        "# Training loop (학습 반복문)\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = 0.0  # 훈련 손실 초기화\n",
        "    train_correct = 0  # 훈련 예측 정확도 초기화\n",
        "    train_total = 0  # 훈련 데이터 총 개수 초기화\n",
        "\n",
        "    net.train()  # 모델을 훈련 모드로 설정\n",
        "\n",
        "    # Training phase (훈련 단계)\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)  # 입력 데이터를 디바이스로 이동\n",
        "        labels = labels.to(DEVICE)  # 레이블을 디바이스로 이동\n",
        "\n",
        "        optimizer.zero_grad()  # 그래디언트 초기화\n",
        "\n",
        "        # Forward pass (순전파)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)  # 손실 계산\n",
        "\n",
        "        # Backward pass and optimization (역전파 및 최적화)\n",
        "        loss.backward()  # 역전파 수행\n",
        "        optimizer.step()  # 가중치 업데이트\n",
        "\n",
        "        # Compute accuracy (정확도 계산)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item()  # 훈련 손실 누적\n",
        "\n",
        "    train_loss /= len(train_loader)  # 훈련 손실 평균 계산\n",
        "    train_accuracy = 100 * train_correct / train_total  # 훈련 정확도 계산\n",
        "\n",
        "    val_loss = 0.0  # 검증 손실 초기화\n",
        "    val_correct = 0  # 검증 예측 정확도 초기화\n",
        "    val_total = 0  # 검증 데이터 총 개수 초기화\n",
        "\n",
        "    net.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "    # Validation phase (검증 단계)\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(DEVICE)  # 입력 데이터를 디바이스로 이동\n",
        "            labels = labels.to(DEVICE)  # 레이블을 디바이스로 이동\n",
        "\n",
        "            # Forward pass (순전파)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)  # 손실 계산\n",
        "\n",
        "            # Compute accuracy (정확도 계산)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss += loss.item()  # 검증 손실 누적\n",
        "\n",
        "    val_loss /= len(val_loader)  # 검증 손실 평균 계산\n",
        "    val_accuracy = 100 * val_correct / val_total  # 검증 정확도 계산\n",
        "\n",
        "    # Print statistics for the current epoch (현재 에포크의 통계 출력)\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn7s1UZmsHgc"
      },
      "source": [
        "# nn.Module의 가중치 저장\n",
        "\n",
        "`nn.Module`은 파이토치에서 신경망 모델을 구축하는 데 사용되는 기본 클래스입니다. `nn.Module`을 사용하여 정의한 모델은 학습 가능한 파라미터인 가중치(weight)와 편향(bias)을 가지고 있습니다. 이 가중치들은 학습을 통해 업데이트되며 모델의 예측에 사용됩니다.\n",
        "\n",
        "`nn.Module`의 가중치를 저장하는 방법은 다음과 같습니다:\n",
        "\n",
        "1. **state_dict() 메서드**: `nn.Module` 객체의 `state_dict()` 메서드를 호출하여 가중치들을 딕셔너리 형태로 가져올 수 있습니다. 이 딕셔너리에는 각 가중치의 이름과 해당 가중치의 값이 저장됩니다.\n",
        "\n",
        "2. **torch.save() 함수**: `torch.save()` 함수를 사용하여 `state_dict()`로 얻은 가중치 딕셔너리를 파일로 저장할 수 있습니다. 저장된 파일은 나중에 모델을 로드하여 가중치를 복원하는 데 사용될 수 있습니다.\n",
        "\n",
        "아래는 nn.Module의 가중치를 저장하는 예제입니다:\n",
        "\n",
        "```python\n",
        "# 모델의 가중치 저장\n",
        "torch.save(model.state_dict(), 'model_weights.pth')\n",
        "```\n",
        "\n",
        "위 예제에서 `model`은 `nn.Module`로 구성된 모델 객체입니다. `state_dict()` 메서드를 호출하여 모델의 가중치를 딕셔너리 형태로 가져오고, `torch.save()` 함수를 사용하여 이 가중치 딕셔너리를 `'model_weights.pth'`라는 파일에 저장합니다.\n",
        "\n",
        "이렇게 저장된 가중치는 나중에 `torch.load()` 함수를 사용하여 로드할 수 있으며, 모델에 복원된 가중치를 적용할 수 있습니다. 가중치를 로드하는 방법은 다음과 같습니다:\n",
        "\n",
        "```python\n",
        "# 저장된 가중치 로드\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "```\n",
        "\n",
        "위 예제에서 `model`은 로드할 모델 객체입니다. `torch.load()` 함수를 사용하여 `'model_weights.pth'` 파일에서 가중치 딕셔너리를 로드하고, `load_state_dict()` 메서드를 사용하여 모델에 가중치를 복원합니다.\n",
        "\n",
        "가중치를 저장하고 로드함으로써, 학습된 모델을 나중에 다시 사용하거나 전이 학습(transfer learning) 등을 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFTWMegHsHgc"
      },
      "outputs": [],
      "source": [
        "WEIGHT_PATH = \"LinearModel_weights.pth\"\n",
        "torch.save(net.state_dict(), WEIGHT_PATH)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}